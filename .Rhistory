# Clean term names for display.
term_clean = str_replace(term, "factor\\(month_num\\)", "Month ") %>%
str_replace("factor\\(racial_majority\\)", "") %>%
str_replace("filings_", "Lag: ") %>%
str_replace("spatial_lag_filings", "Spatial Lag (Lagged)") %>%
str_replace("log_avg_balance", "Tax Delinquency (Log)") %>%
str_replace("pct_renter", "ACS: % Renter") %>%
str_replace("poverty_rate", "ACS: Poverty Rate") %>%
str_replace("severe_rent_burden", "ACS: Severe Rent Burden") %>%
str_replace("unemployment_rate", "ACS: Unemployment Rate") %>%
str_replace("log_median_income", "ACS: Median Income (Log)") %>%
str_replace("pct_single_mother", "ACS: % Single Mother HH"),
# Identify feature category.
category = case_when(
str_detect(term_clean, "Lag") ~ "Temporal",
str_detect(term_clean, "Spatial") ~ "Spatial",
str_detect(term_clean, "ACS") ~ "Socioeconomic (ACS)",
str_detect(term_clean, "Tax") ~ "Tax Delinquency",
str_detect(term_clean, "Month") ~ "Seasonality",
str_detect(term_clean, "Moratorium") ~ "Policy",
TRUE ~ "Demographic"
)
) %>%
arrange(desc(abs_estimate)) %>%
head(20)
# Create feature importance plot.
importance_plot <- feature_importance %>%
ggplot(aes(x = reorder(term_clean, abs_estimate), y = estimate, fill = category)) +
geom_col(width = 0.7) +
coord_flip() +
scale_fill_brewer(palette = "Set2") +
labs(
title = "Top 20 Most Important Predictors",
subtitle = "Coefficient magnitude indicates effect size on log(expected filings)",
x = "Predictor Variable",
y = "Coefficient Estimate",
fill = "Category",
caption = "Enhanced Negative Binomial Regression Coefficients (including ACS indicators)"
) +
theme_minimal(base_size = 12) +
theme(
plot.title = element_text(face = "bold", size = 14),
legend.position = "bottom"
)
# Display importance plot.
importance_plot
# Specifically analyze contribution of ACS features.
acs_contribution <- broom::tidy(model_nb_enhanced) %>%
filter(str_detect(term, "pct_renter|poverty_rate|severe_rent_burden|unemployment_rate")) %>%
mutate(
irr = exp(estimate),
pct_change = (irr - 1) * 100,
significant = ifelse(p.value < 0.05, "Yes", "No")
) %>%
dplyr::select(term, estimate, std.error, p.value, irr, pct_change, significant)
acs_contribution %>%
kable(digits = 3, caption = "ACS Socioeconomic Feature Effects") %>%
kable_styling(bootstrap_options = c("striped", "hover"))
# Calculate incidence rate ratios for interpretation.
irr_table <- broom::tidy(model_nb_enhanced) %>%
mutate(
irr = exp(estimate),
irr_lower = exp(estimate - 1.96 * std.error),
irr_upper = exp(estimate + 1.96 * std.error),
pct_change = (irr - 1) * 100
) %>%
filter(term != "(Intercept)") %>%
dplyr::select(term, irr, irr_lower, irr_upper, pct_change, p.value)
irr_table %>%
head(15) %>%
kable(digits = 3, caption = "Incidence Rate Ratios (IRR) for Key Predictors") %>%
kable_styling(bootstrap_options = c("striped", "hover"))
# Create actionable output for city agencies with intervention thresholds.
operational_output <- df_test_pred %>%
filter(predicted >= 5) %>%
group_by(GEOID) %>%
summarize(
predicted_filings_next_month = mean(predicted),
n_high_risk_months = n(),
.groups = "drop"
) %>%
left_join(df_acs, by = "GEOID") %>%
arrange(desc(predicted_filings_next_month))
operational_output
#| fig-dpi: 300
#| fig-height: 7
#| fig-width: 12
# Calculate prediction errors by racial majority to assess disparate impact.
equity_metrics <- df_test_pred %>%
filter(!is.na(racial_majority), racial_majority != "") %>%
group_by(racial_majority) %>%
summarize(
n_obs = n(),
mean_observed = mean(filings_count, na.rm = TRUE),
mean_predicted = mean(predicted, na.rm = TRUE),
mae = mean(abs_error, na.rm = TRUE),
mean_error = mean(residual, na.rm = TRUE),
under_prediction_rate = sum(residual > 0) / n() * 100,
.groups = "drop"
)
# Display equity metrics table.
equity_metrics %>%
kable(digits = 2, caption = "Model Performance Metrics by Tract Racial Majority") %>%
kable_styling(bootstrap_options = c("striped", "hover"))
#| fig-dpi: 300
#| fig-height: 6
#| fig-width: 12
# Create plot comparing MAE across racial categories.
equity_plot <- equity_metrics %>%
ggplot(aes(x = racial_majority, y = mae, fill = racial_majority)) +
geom_col(width = 0.7) +
geom_text(aes(label = sprintf("%.2f", mae)), vjust = -0.5, size = 4) +
scale_fill_manual(values = racial_colors) +
scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +
labs(
title = "Model Accuracy (MAE) by Tract Racial Majority",
subtitle = "Lower values indicate better prediction accuracy",
x = "Tract Racial Majority",
y = "Mean Absolute Error",
caption = "Data: Philadelphia Eviction Filings 2024-2025 Test Set"
) +
theme_minimal(base_size = 12) +
theme(
plot.title = element_text(face = "bold", size = 14),
legend.position = "none"
)
# Display equity plot.
equity_plot
#| fig-dpi: 300
#| fig-height: 8
#| fig-width: 12
# Create calibration plot showing predicted vs observed by racial majority.
calibration_plot <- df_test_pred %>%
filter(!is.na(racial_majority), racial_majority != "") %>%
mutate(predicted_bin = cut(predicted, breaks = seq(0, 15, by = 1), include.lowest = TRUE)) %>%
filter(!is.na(predicted_bin)) %>%
group_by(racial_majority, predicted_bin) %>%
summarize(
mean_predicted = mean(predicted, na.rm = TRUE),
mean_observed = mean(filings_count, na.rm = TRUE),
n = n(),
.groups = "drop"
) %>%
filter(n >= 10) %>%
ggplot(aes(x = mean_predicted, y = mean_observed, color = racial_majority)) +
geom_point(aes(size = n), alpha = 0.7) +
geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
scale_color_manual(values = racial_colors) +
scale_size_continuous(range = c(2, 8)) +
labs(
title = "Model Calibration by Tract Racial Majority",
subtitle = "Points on diagonal indicate well-calibrated predictions",
x = "Mean Predicted Filings",
y = "Mean Observed Filings",
color = "Racial\nMajority",
size = "N Obs",
caption = "Data: Philadelphia Eviction Filings 2024-2025 Test Set"
) +
theme_minimal(base_size = 12) +
theme(
plot.title = element_text(face = "bold", size = 14),
legend.position = "right"
)
# Display calibration plot.
calibration_plot
#| fig-dpi: 300
#| fig-height: 7
#| fig-width: 12
# Calculate risk category distribution by racial majority.
risk_by_race <- df_test_risk %>%
filter(!is.na(racial_majority), racial_majority != "") %>%
group_by(racial_majority, risk_category) %>%
summarize(n = n(), .groups = "drop") %>%
group_by(racial_majority) %>%
mutate(pct = n / sum(n) * 100) %>%
ungroup()
# Create stacked bar plot.
risk_race_plot <- risk_by_race %>%
ggplot(aes(x = racial_majority, y = pct, fill = risk_category)) +
geom_col(width = 0.7) +
scale_fill_viridis_d(option = "plasma", direction = -1) +
scale_y_continuous(labels = percent_format(scale = 1)) +
labs(
title = "Distribution of Risk Categories by Tract Racial Majority",
subtitle = "Black-majority tracts disproportionately classified as high risk",
x = "Tract Racial Majority",
y = "Percentage of Tract-Months",
fill = "Risk\nCategory",
caption = "Data: Philadelphia Eviction Filings 2024-2025 Test Set"
) +
theme_minimal(base_size = 12) +
theme(
plot.title = element_text(face = "bold", size = 14),
legend.position = "right"
)
# Display risk by race plot.
risk_race_plot
#| fig-dpi: 300
#| fig-height: 6
#| fig-width: 12
# Create equity comparison plot.
equity_plot <- equity_metrics %>%
pivot_longer(cols = c(mean_observed, mean_predicted),
names_to = "type", values_to = "value") %>%
mutate(type = ifelse(type == "mean_observed", "observed", "predicted")) %>%
ggplot(aes(x = racial_majority, y = value, fill = type)) +
geom_col(position = "dodge", width = 0.7) +
scale_fill_manual(values = c("observed" = "#E74C3C", "predicted" = "#3498DB")) +
labs(
title = "Model Calibration by Racial Majority: Observed vs Predicted",
subtitle = "Close alignment indicates equitable prediction accuracy across communities",
x = "Tract Racial Majority",
y = "Mean Filings per Tract-Month",
fill = "type",
caption = "Data: Philadelphia Eviction Filings 2024-2025 Test Set"
) +
theme_minimal(base_size = 12) +
theme(
plot.title = element_text(face = "bold", size = 14),
legend.position = "bottom"
)
# Display equity plot.
equity_plot
# Compile comprehensive summary stats.
summary_stats <- df_monthly %>%
filter(GEOID != "sealed", !is.na(GEOID), GEOID != "") %>%
summarize(
total_obs = n(),
unique_tracts = n_distinct(GEOID),
unique_months = n_distinct(date),
mean_filings = mean(filings_count, na.rm = TRUE),
median_filings = median(filings_count, na.rm = TRUE),
sd_filings = sd(filings_count, na.rm = TRUE),
min_filings = min(filings_count, na.rm = TRUE),
max_filings = max(filings_count, na.rm = TRUE),
zero_pct = sum(filings_count == 0) / n() * 100,
dispersion = var(filings_count) / mean(filings_count)
)
summary_stats %>%
pivot_longer(everything(), names_to = "statistic", values_to = "value") %>%
mutate(value = round(value, 2)) %>%
kable(caption = "Summary Statistics") %>%
kable_styling(bootstrap_options = c("striped", "hover"))
# Document R session information for reproducibility.
sessionInfo()
# Compare model fit statistics.
model_comparison <- data.frame(
model = c("Baseline", "+ Tax and Spatial", "+ ACS", "+ Interactions"),
aic = c(AIC(model_nb_1), AIC(model_nb_2), AIC(model_nb_3), AIC(model_nb_4)),
theta = c(model_nb_1$theta, model_nb_2$theta, model_nb_3$theta, model_nb_4$theta),
loglik = c(logLik(model_nb_1), logLik(model_nb_2), logLik(model_nb_3), logLik(model_nb_4))
) %>%
mutate(
aic_change = aic - min(aic),
rank = rank(aic)
)
model_comparison %>%
kable(digits = 2, caption = "Model Comparison Statistics (Lower AIC = Better Fit)") %>%
kable_styling(bootstrap_options = c("striped", "hover"))
library(tidyverse)
library(lubridate)
library(sf)
library(scales)
library(patchwork)
library(viridis)
library(kableExtra)
library(corrplot)
library(zoo)
library(MASS)
library(car)
library(caret)
library(pROC)
library(spdep)
library(tidycensus)
library(httr)
library(jsonlite)
library(glue)
library(dplyr)
library(stringr)
library(tidyr)
# Disable scientific notation.
options(scipen = 999)
carto_base <- "https://phl.carto.com/api/v2/sql"
# Helper to run a Carto SQL query and return a tibble.
carto_query <- function(sql) {
resp <- GET(carto_base, query = list(q = sql))
stop_for_status(resp)
txt <- content(resp, as = "text", encoding = "UTF-8")
json <- fromJSON(txt, flatten = TRUE)
as_tibble(json$rows)
}
# Pull assessment history aggregated to census_tract-year.
sql_assessments_by_tract_year <- "
SELECT
census_tract,
EXTRACT(YEAR FROM assessment_date) AS year,
COUNT(*) AS n_assess_records,
AVG(market_value) AS mean_market_value,
AVG(taxable_building) AS mean_taxable_building,
AVG(taxable_land) AS mean_taxable_land,
AVG(exempt_building) AS mean_exempt_building,
AVG(exempt_land) AS mean_exempt_land,
AVG(year_built) AS mean_year_built
FROM assessments
WHERE assessment_date >= '2020-01-01'
AND assessment_date <  '2026-01-01'
AND census_tract IS NOT NULL
GROUP BY census_tract, year
ORDER BY census_tract, year
"
df_opa_yearly_raw <- carto_query(sql_assessments_by_tract_year)
carto_base <- "https://phl.carto.com/api/v2/sql"
# Helper to run a Carto SQL query and return a tibble.
carto_query <- function(sql) {
resp <- GET(carto_base, query = list(q = sql))
stop_for_status(resp)
txt <- content(resp, as = "text", encoding = "UTF-8")
json <- fromJSON(txt, flatten = TRUE)
as_tibble(json$rows)
}
# Pull assessment history aggregated to census_tract-year.
sql_assessments_by_tract_year <- "
SELECT
census_tract,
EXTRACT(YEAR FROM assessment_date) AS year,
COUNT(*) AS n_assess_records,
AVG(market_value) AS mean_market_value,
AVG(taxable_building) AS mean_taxable_building,
AVG(taxable_land) AS mean_taxable_land,
AVG(exempt_building) AS mean_exempt_building,
AVG(exempt_land) AS mean_exempt_land,
AVG(year_built) AS mean_year_built
FROM opa_property_assessments
WHERE assessment_date >= '2020-01-01'
AND assessment_date <  '2026-01-01'
AND census_tract IS NOT NULL
GROUP BY census_tract, year
ORDER BY census_tract, year
"
df_opa_yearly_raw <- carto_query(sql_assessments_by_tract_year)
test_sql <- "SELECT * FROM opa_property_assessments LIMIT 5"
carto_query(test_sql)
test_sql2 <- "SELECT parcel_number, census_tract FROM opa_properties_public LIMIT 5"
carto_query(test_sql2)
carto_base <- "https://phl.carto.com/api/v2/sql"
# Helper to run a Carto SQL query and return a tibble.
carto_query <- function(sql) {
resp <- GET(carto_base, query = list(q = sql))
stop_for_status(resp)
txt <- content(resp, as = "text", encoding = "UTF-8")
json <- fromJSON(txt, flatten = TRUE)
as_tibble(json$rows)
}
# Pull assessment history aggregated to census_tract-year.
sql_assessments_by_tract_year <- "
SELECT
census_tract,
EXTRACT(YEAR FROM assessment_date) AS year,
COUNT(*) AS n_assess_records,
AVG(market_value) AS mean_market_value,
AVG(taxable_building) AS mean_taxable_building,
AVG(taxable_land) AS mean_taxable_land,
AVG(exempt_building) AS mean_exempt_building,
AVG(exempt_land) AS mean_exempt_land,
AVG(year_built) AS mean_year_built
FROM opa_properties_public
WHERE assessment_date >= '2020-01-01'
AND assessment_date <  '2026-01-01'
AND census_tract IS NOT NULL
GROUP BY census_tract, year
ORDER BY census_tract, year
"
df_opa_yearly_raw <- carto_query(sql_assessments_by_tract_year)
test_sql2 <- "SELECT parcel_number, census_tract FROM opa_properties_public LIMIT 5"
carto_query(test_sql2)
carto_base <- "https://phl.carto.com/api/v2/sql"
# Helper to run a Carto SQL query and return a tibble.
carto_query <- function(sql) {
resp <- GET(carto_base, query = list(q = sql))
stop_for_status(resp)
txt <- content(resp, as = "text", encoding = "UTF-8")
json <- fromJSON(txt, flatten = TRUE)
as_tibble(json$rows)
}
# Pull assessment history aggregated to census_tract-year.
sql_assessments_by_tract_year <- "
SELECT
census_tract,
EXTRACT(YEAR FROM assessment_date) AS year,
COUNT(*) AS n_assess_records,
AVG(market_value) AS mean_market_value,
AVG(taxable_building) AS mean_taxable_building,
AVG(taxable_land) AS mean_taxable_land,
AVG(exempt_building) AS mean_exempt_building,
AVG(exempt_land) AS mean_exempt_land,
AVG(year_built) AS mean_year_built
FROM opa_properties_public
WHERE assessment_date >= '2020-01-01'
AND assessment_date <  '2026-01-01'
AND census_tract IS NOT NULL
GROUP BY census_tract, year
ORDER BY census_tract, year
"
df_opa_yearly_raw <- carto_query(sql_assessments_by_tract_year)
carto_base <- "https://phl.carto.com/api/v2/sql"
# Helper to run a Carto SQL query and return a tibble.
carto_query <- function(sql) {
resp <- GET(carto_base, query = list(q = sql))
stop_for_status(resp)
txt <- content(resp, as = "text", encoding = "UTF-8")
json <- fromJSON(txt, flatten = TRUE)
as_tibble(json$rows)
}
# Pull assessment history aggregated to census_tract-year.
sql_assessments_by_tract <- "
SELECT
census_tract,
COUNT(*) AS n_properties,
AVG(market_value) AS mean_market_value,
AVG(taxable_building) AS mean_taxable_building,
AVG(taxable_land) AS mean_taxable_land,
AVG(exempt_building) AS mean_exempt_building,
AVG(exempt_land) AS mean_exempt_land,
AVG(year_built) AS mean_year_built,
PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY market_value) AS median_market_value,
PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY year_built) AS median_year_built
FROM opa_properties_public
WHERE assessment_date >= '2020-01-01'
AND census_tract IS NOT NULL
GROUP BY census_tract
ORDER BY census_tract
"
df_opa_yearly_raw <- carto_query(sql_assessments_by_tract_year)
carto_base <- "https://phl.carto.com/api/v2/sql"
# Helper to run a Carto SQL query and return a tibble.
carto_query <- function(sql) {
resp <- GET(carto_base, query = list(q = sql))
stop_for_status(resp)
txt <- content(resp, as = "text", encoding = "UTF-8")
json <- fromJSON(txt, flatten = TRUE)
as_tibble(json$rows)
}
# Pull assessment history aggregated to census_tract-year.
sql_assessments_2023 <- "
SELECT
census_tract,
COUNT(*) AS n_properties,
AVG(market_value) AS mean_market_value,
AVG(year_built) AS mean_year_built
FROM opa_properties_public
WHERE EXTRACT(YEAR FROM assessment_date) = 2023
AND census_tract IS NOT NULL
GROUP BY census_tract
ORDER BY census_tract
"
df_opa_yearly_raw <- carto_query(sql_assessments_by_tract_year)
View(df_model_prep)
#| fig-dpi: 300
#| fig-height: 10
#| fig-width: 10
# Extract standardized coefficients for interpretation.
feature_importance <- broom::tidy(model_nb_enhanced) %>%
filter(term != "(Intercept)") %>%
mutate(
abs_estimate = abs(estimate),
direction = ifelse(estimate > 0, "Positive", "Negative"),
# Clean term names for display.
term_clean = str_replace(term, "factor\\(month_num\\)", "Month ") %>%
str_replace("factor\\(racial_majority\\)", "") %>%
str_replace("filings_", "Lag: ") %>%
str_replace("spatial_lag_filings", "Spatial Lag (Lagged)") %>%
str_replace("log_avg_balance", "Tax Delinquency (Log)") %>%
str_replace("pct_renter", "ACS: % Renter") %>%
str_replace("poverty_rate", "ACS: Poverty Rate") %>%
str_replace("severe_rent_burden", "ACS: Severe Rent Burden") %>%
str_replace("unemployment_rate", "ACS: Unemployment Rate") %>%
str_replace("log_median_income", "ACS: Median Income (Log)") %>%
str_replace("pct_single_mother", "ACS: % Single Mother HH"),
# Identify feature category.
category = case_when(
str_detect(term_clean, "Lag") ~ "Temporal",
str_detect(term_clean, "Spatial") ~ "Spatial",
str_detect(term_clean, "ACS") ~ "Socioeconomic (ACS)",
str_detect(term_clean, "Tax") ~ "Tax Delinquency",
str_detect(term_clean, "Month") ~ "Seasonality",
str_detect(term_clean, "Moratorium") ~ "Policy",
TRUE ~ "Demographic"
)
) %>%
arrange(desc(abs_estimate)) %>%
head(20)
# Create feature importance plot.
importance_plot <- feature_importance %>%
ggplot(aes(x = reorder(term_clean, abs_estimate), y = estimate, fill = category)) +
geom_col(width = 0.7) +
coord_flip() +
scale_fill_brewer(palette = "Set2") +
labs(
title = "Top 20 Most Important Predictors",
subtitle = "Coefficient magnitude indicates effect size on log(expected filings)",
x = "Predictor Variable",
y = "Coefficient Estimate",
fill = "Category",
caption = "Enhanced Negative Binomial Regression Coefficients (including ACS indicators)"
) +
theme_minimal(base_size = 12) +
theme(
plot.title = element_text(face = "bold", size = 14),
legend.position = "bottom"
)
# Display importance plot.
importance_plot
